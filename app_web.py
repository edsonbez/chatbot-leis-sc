import streamlit as st
import time
import sys
import os


# Adiciona o diretÃ³rio raiz do projeto (onde estÃ¡ o app_web.py) ao caminho de busca do Python
# Isso garante que a importaÃ§Ã£o 'src.rag_service' funcione localmente.
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
# ------------------------------------------------------------------
# CRÃTICO: Importa o mÃ³dulo de serviÃ§o RAG (antigo chatbot.py).
try:
    # Acessa o novo arquivo rag_service dentro da pasta src
    import src.rag_service as chatbot
except ImportError as e:
    st.error(f"Erro: NÃ£o foi possÃ­vel importar o mÃ³dulo 'src.rag_service'. Verifique a nova estrutura de pastas. Detalhe: {e}")
    st.stop()


# --- ConfiguraÃ§Ã£o da PÃ¡gina Streamlit ---
st.set_page_config(
    page_title="Chatbot JurÃ­dico de SC",
    page_icon="âš–ï¸",
    layout="wide"
)

st.title("âš–ï¸ Chatbot de Consultoria JurÃ­dica - Leis de Santa Catarina")
st.markdown("Este assistente Ã© especializado em responder perguntas **exclusivamente** com base nas leis estaduais de Santa Catarina.")

# --- InicializaÃ§Ã£o da Base de Dados e Cliente (Caching) ---
@st.cache_resource
def setup_chatbot():
    """
    Inicializa os clientes da API e do Banco de Dados Vetorial.
    Tudo Ã© executado APENAS UMA VEZ.
    """
    
    # 1. RECUPERAÃ‡ÃƒO SEGURA DA CHAVE DE API
    try:
        # Tenta carregar a chave da seÃ§Ã£o [secrets]
        api_key = st.secrets["GEMINI_API_KEY"]
    except KeyError:
        return "Erro CRÃTICO: A chave 'GEMINI_API_KEY' nÃ£o foi encontrada nos Segredos (Secrets) do Streamlit. Por favor, configure-a no painel do Streamlit Cloud."
    
    # 2. INICIALIZAÃ‡ÃƒO DO CHATBOT (FAISS e Cliente Gemini)
    try:
        # Chama a funÃ§Ã£o principal de inicializaÃ§Ã£o no chatbot.py, passando a chave segura
        # initialize_chromadb chamarÃ¡ initialize_gemini_client internamente.
        chatbot.initialize_chromadb(api_key) 
        
        return "Pronto para consultas."
    except Exception as e:
        # Captura e retorna erros de inicializaÃ§Ã£o (ex: arquivo FAISS ausente/corrompido)
        return f"Erro na inicializaÃ§Ã£o: {e}. Verifique se o Ã­ndice FAISS e o Mapa de Documentos existem e nÃ£o estÃ£o corrompidos."


# Exibe o status de inicializaÃ§Ã£o e interrompe se houver erro
status = setup_chatbot()
if "Erro" in status:
    st.error(status)
    st.stop()

# --------------------------------------------------------------------------
# FunÃ§Ã£o de limpeza do histÃ³rico.
def clear_chat_history():
    """Limpa a sessÃ£o de chat do Streamlit."""
    
    # Limpa o histÃ³rico do Streamlit
    st.session_state.messages = []
    # Adiciona a mensagem inicial novamente
    st.session_state.messages.append({"role": "assistant", "content": "OlÃ¡! Sou seu assistente jurÃ­dico especializado em Leis de Santa Catarina. Como posso ajudar na sua consulta legal hoje?"})
# --------------------------------------------------------------------------

# 1. INICIALIZA O ESTADO DA SESSÃƒO PARA O HISTÃ“RICO
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Adiciona uma mensagem inicial de boas-vindas
    st.session_state.messages.append({"role": "assistant", "content": "OlÃ¡! Sou seu assistente jurÃ­dico especializado em Leis de Santa Catarina. Como posso ajudar na sua consulta legal hoje?"})


# 2. EXIBE O HISTÃ“RICO DE MENSAGENS NO CHAT
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Garante que a mensagem Ã© sempre Markdown
        # O conteÃºdo agora inclui o footer, garantindo a persistÃªncia das fontes
        st.markdown(message["content"])

# --- LÃ³gica de Consulta e Resposta (COM STREAMING) ---
if prompt := st.chat_input("FaÃ§a sua pergunta sobre as Leis de SC:"):
    
    # 3. Adiciona a pergunta do usuÃ¡rio ao histÃ³rico e exibe
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Prepara o histÃ³rico para o filtro de intenÃ§Ã£o e reescrita de query
    # Ã‰ CRÃTICO que o histÃ³rico para o chatbot seja uma lista de tuplas (role, content)
    history_for_context = [
        (msg["role"], msg["content"]) 
        for msg in st.session_state.messages
    ]

    # 4. Chama a funÃ§Ã£o de resposta
    with st.chat_message("assistant"):
        
        # Cria um contÃªiner para a resposta e o footer (fontes/tempo)
        response_container = st.container()
        
        # Placeholder ÃšNICO: Para o stream e o conteÃºdo final (texto + footer)
        text_placeholder = response_container.empty()
        
        start_time = time.time()
        
        try:
            # AQUI ESTÃ A CHAMADA CORRIGIDA: A funÃ§Ã£o get_response espera 2 argumentos.
            response_result, cited_sources = chatbot.get_response(
                prompt, 
                history_for_context
            ) 
        except Exception as e:
            response_result = f"Ocorreu um erro inesperado no back-end: {e}"
            cited_sources = set()


        # >>> LÃ“GICA DE CONSUMO DO STREAM/STRING <<<
        
        full_response = ""
        
        # Se o resultado for uma STRING (erro ou filtro NAO_JURIDICA), exibe de uma vez.
        if isinstance(response_result, str):
            full_response = response_result
            # NÃ£o exibe ainda, pois o footer serÃ¡ anexado
        
        # Se o resultado for um ITERATOR/STREAM (resposta bem-sucedida do Gemini)
        else:
            # st.write_stream usa a funÃ§Ã£o geradora para exibir o texto e retorna o resultado completo
            with text_placeholder.container():
                full_response = st.write_stream(chatbot.text_generator(response_result))

        # ----------------------------------------------------------------------
        
        end_time = time.time()
        
        # 5. ConstrÃ³i o Footer (Fontes e Tempo) e anexa Ã  resposta.
        
        # Inicia o conteÃºdo do footer com a linha divisÃ³ria e o tempo
        footer_content = f"\n\n--- \nTempo de resposta: **{end_time - start_time:.2f} segundos**"
        
        if cited_sources:
            sources_list = "\n".join([f"- {source}" for source in sorted(list(cited_sources))])
            footer_content += f"\n\n**Fontes Recuperadas:**\n{sources_list}"
        else:
            # Verifica se foi uma resposta de filtro ou erro para dar o feedback correto
            if "nÃ£o foi encontrada nos documentos" in full_response or "nÃ£o-jurÃ­dica" in full_response:
                footer_content += "\n\n**Fontes Recuperadas:** Nenhuma fonte no corpus foi utilizada."
            else:
                footer_content += "\n\n**Fontes Recuperadas:** Nenhuma fonte foi citada (possÃ­vel erro)." 

        # Anexa o footer Ã  resposta completa do LLM
        full_response_with_footer = full_response + footer_content
        
        # 6. Atualiza o placeholder com a resposta completa + footer.
        # Isso garante que o footer apareÃ§a logo apÃ³s o texto, finalizando a mensagem.
        text_placeholder.markdown(full_response_with_footer)


        # 7. Salva a resposta COMPLETA (texto + footer) no histÃ³rico (IMPORTANTE)
        st.session_state.messages.append({"role": "assistant", "content": full_response_with_footer})

# --- Footer EstÃ¡tico ---
st.sidebar.markdown("---")
# O botÃ£o para limpar a conversa
st.sidebar.button('ðŸ—‘ï¸ Limpar Conversa (Resetar MemÃ³ria)', on_click=clear_chat_history)
st.sidebar.markdown("---")
st.sidebar.markdown(f"**Status da Base de Dados:** {status}")
st.sidebar.markdown("Desenvolvido para anÃ¡lise jurÃ­dica de Leis do Estado de Santa Catarina.")